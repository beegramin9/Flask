{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "자연어 처리\n",
    "문자로 된 글은 컴퓨터가 읽을 수 없으니 숫자로 바꿔준다\n",
    "방법 중 하나가 bag of words, 이 안에 count벡터랑 tfidf벡터랑\n",
    "이거 한 다음에 분류기(SVC, LR) 등으로 분류함\n",
    "\n",
    "벡터랑 분류를 한 번에 하는게 Pipeline\n",
    "여기다 하이퍼 파라미터 튜닝 하려면 gridSearchcv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import re\n",
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>sentiment</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\"5814_8\"</td>\n      <td>1</td>\n      <td>\"With all this stuff going down at the moment ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"2381_9\"</td>\n      <td>1</td>\n      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\"7759_3\"</td>\n      <td>0</td>\n      <td>\"The film starts with a manager (Nicholas Bell...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df_raw = pd.read_csv('../static/data/advanced/labeledTrainData.tsv',\n",
    "                header = 0, sep = '\\t', quoting = 3)\n",
    "df_raw.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 25000 entries, 0 to 24999\nData columns (total 3 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   id         25000 non-null  object\n 1   sentiment  25000 non-null  int64 \n 2   review     25000 non-null  object\ndtypes: int64(1), object(2)\nmemory usage: 586.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <br>(띄어쓰기)는 공백으로 변환\n",
    "df_raw['review'] = df_raw['review'].str.replace('<br />',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영어 이외의 문자는 공백으로 변환\n",
    "df_raw['review'] = df_raw.review.apply(lambda x: re.sub('[^a-zA-Z]', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "id           0\n",
       "sentiment    0\n",
       "review       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "df_raw.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "id           0\n",
       "sentiment    0\n",
       "review       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df_raw[df_raw.review == ''].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = df_raw.drop(['id','sentiment'], axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    review_df, df_raw.sentiment, test_size = 0.25, random_state = 2021\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                  review\n",
       "14475   There s no shortage of bad dialogue in David ...\n",
       "22605   This film takes what could have been a good i...\n",
       "17673   Bob Clampett s  Porky s Poor Fish  is a so so..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14475</th>\n      <td>There s no shortage of bad dialogue in David ...</td>\n    </tr>\n    <tr>\n      <th>22605</th>\n      <td>This film takes what could have been a good i...</td>\n    </tr>\n    <tr>\n      <th>17673</th>\n      <td>Bob Clampett s  Porky s Poor Fish  is a so so...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "X_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                  review\n",
       "13895   I was expecting a B Movie French musical  Aft...\n",
       "20903   Disappearance is about a couple who take thei...\n",
       "8539    I noticed at once that this movie really wasn..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>13895</th>\n      <td>I was expecting a B Movie French musical  Aft...</td>\n    </tr>\n    <tr>\n      <th>20903</th>\n      <td>Disappearance is about a couple who take thei...</td>\n    </tr>\n    <tr>\n      <th>8539</th>\n      <td>I noticed at once that this movie really wasn...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "print(type(X_test))\n",
    "X_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                  review  sentiment\n",
       "13895   I was expecting a B Movie French musical  Aft...          0\n",
       "20903   Disappearance is about a couple who take thei...          0\n",
       "8539    I noticed at once that this movie really wasn...          1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>13895</th>\n      <td>I was expecting a B Movie French musical  Aft...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20903</th>\n      <td>Disappearance is about a couple who take thei...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8539</th>\n      <td>I noticed at once that this movie really wasn...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "df_test = pd.DataFrame(X_test, columns=['review'])\n",
    "df_test['sentiment'] = y_test\n",
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('../static/data/IMDB_test.csv', index=False)"
   ]
  },
  {
   "source": [
    "1. CountVectorizer + 로지스틱 회귀"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('count_vect', CountVectorizer(stop_words='english', ngram_range=(1,2))),\n",
    "    ('lr_clf', LogisticRegression())\n",
    "])\n",
    "params = ({\n",
    "    'count_vect__max_df': [100, 300, 500],\n",
    "    'lr_clf__C': [1, 5, 10]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:  6.6min finished\n",
      "{'count_vect__max_df': 500, 'lr_clf__C': 1} 0.8667199999999999\n"
     ]
    }
   ],
   "source": [
    "grid_pipe = GridSearchCV(pipeline, param_grid=params, cv=3,\n",
    "                         scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_pipe.fit(X_train.review, y_train)\n",
    "print(grid_pipe.best_params_, grid_pipe.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.87344"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "best_count_lr = grid_pipe.best_estimator_\n",
    "pred_count_lr = best_count_lr.predict(df_test.review.values)\n",
    "accuracy_score(df_test.sentiment.values, pred_count_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['../static/model/imdb_count_lr.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "joblib.dump(best_count_lr, '../static/model/imdb_count_lr.pkl')"
   ]
  },
  {
   "source": [
    "\n",
    "2. CountVectorizer + SVC"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('count_vect', CountVectorizer(stop_words='english', ngram_range=(1,2))),\n",
    "    ('sv_clf', SVC())\n",
    "])\n",
    "params = ({\n",
    "    'count_vect__max_df': [100, 300, 500],\n",
    "    'sv_clf__C': [0.1, 1, 10]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed: 81.5min finished\n",
      "{'count_vect__max_df': 500, 'sv_clf__C': 10} 0.8602666666666666\n"
     ]
    }
   ],
   "source": [
    "grid_pipe = GridSearchCV(pipeline, param_grid=params, cv=3,\n",
    "                         scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_pipe.fit(X_train.review, y_train)\n",
    "print(grid_pipe.best_params_, grid_pipe.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.86688"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "best_count_sv = grid_pipe\n",
    "pred_count_sv = best_count_sv.predict(df_test.review.values)\n",
    "accuracy_score(df_test.sentiment.values, pred_count_sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['../static/model/imdb_count_sv.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "joblib.dump(best_count_sv, '../static/model/imdb_count_sv.pkl')"
   ]
  },
  {
   "source": [
    "3. TfidfVectorizer + LogisticRegression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer(stop_words='english', ngram_range=(1,2))),\n",
    "    ('lr_clf', LogisticRegression())\n",
    "])\n",
    "params = ({\n",
    "    'tfidf_vect__max_df': [100, 300, 500],\n",
    "    'lr_clf__C': [0.1, 1, 10]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:  2.9min finished\n",
      "{'lr_clf__C': 10, 'tfidf_vect__max_df': 500} 0.8776533333333333\n"
     ]
    }
   ],
   "source": [
    "grid_pipe = GridSearchCV(pipeline, param_grid=params, cv=3,\n",
    "                         scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_pipe.fit(X_train.review, y_train)\n",
    "print(grid_pipe.best_params_, grid_pipe.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.88144"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "best_tfidf_lr = grid_pipe.best_estimator_\n",
    "pred_tfidf_lr = best_tfidf_lr.predict(df_test.review.values)\n",
    "accuracy_score(df_test.sentiment.values, pred_tfidf_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['../static/model/imdb_tfidf_lr.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "joblib.dump(best_tfidf_lr, '../static/model/imdb_tfidf_lr.pkl')"
   ]
  },
  {
   "source": [
    "4. TfidfVectorizer + SupportVectorMachine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer(stop_words='english', ngram_range=(1,2))),\n",
    "    ('sv_clf', SVC())\n",
    "])\n",
    "params = ({\n",
    "    'tfidf_vect__max_df': [100, 300, 500],\n",
    "    'sv_clf__C': [0.1, 1, 10]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed: 75.6min finished\n",
      "{'sv_clf__C': 10, 'tfidf_vect__max_df': 500} 0.87488\n"
     ]
    }
   ],
   "source": [
    "grid_pipe = GridSearchCV(pipeline, param_grid=params, cv=3,\n",
    "                         scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_pipe.fit(X_train.review, y_train)\n",
    "print(grid_pipe.best_params_, grid_pipe.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.87984"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "best_tfidf_sv = grid_pipe\n",
    "pred_tfidf_sv = best_tfidf_sv.predict(df_test.review.values)\n",
    "accuracy_score(df_test.sentiment.values, pred_tfidf_sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['../static/model/imdb_tfidf_sv.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "joblib.dump(best_tfidf_sv, '../static/model/imdb_tfidf_sv.pkl')"
   ]
  },
  {
   "source": [
    "왜 test_data = \\[\\] 를 만들고 거기에다 append를 하는가? <br>\n",
    "그냥 나오는건 string이라서 <br>\n",
    "\n",
    "pipeline은 벡터라이저 + 분류기<br>\n",
    "\n",
    "벡터라이저에는 \\['문자열','문자열','문자열'\\] 로 들어가야함<br>\n",
    "그렇다고 list(스트링) 하면 한 글자씩 다 잘라서 나옴<br>\n",
    "\n",
    "예로 \\['length=20인 놈','12','13'\\] 이 들어가면 자동적으로 차원이 (3,45) 이런식으로\n",
    "2차원이 되기때문에\n",
    "분류기에 자동적으로 들어갈 수 있음<br>\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 테스트"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' i say the domino principle is an enormously underappreciated film anyone who has taken the time to investigate our contemporary history of conspiracies jfk  rfk  mlk g wallace and in fact numerous others can only draw the conclusion that the author of the domino principle really knew what he was talking about roy tucker could be lee harvey oswald or james earl ray or sirhan sirhan or arthur bremer maybe even john hinkley or timothy mcveigh to mention a few the conspiracy scenario involving spies  big business and political assassinations is not really a fiction but an ominous part of our convoluted existential history god help us but the domino principle is more fact than fantasy if this causes a little loss of sleep  maybe it should don t take my word for it investigate for yourselves  '"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "df_test.iloc[index, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "test_data.append(df_test.iloc[index, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "label = df_test.sentiment[index]\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cl = joblib.load('../static/model/imdb_count_lr.pkl')\n",
    "model_cs = joblib.load('../static/model/imdb_count_sv.pkl')\n",
    "model_tl = joblib.load('../static/model/imdb_tfidf_lr.pkl')\n",
    "model_ts = joblib.load('../static/model/imdb_tfidf_sv.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cl = model_cl.predict(test_data)\n",
    "pred_cs = model_cs.predict(test_data)\n",
    "pred_tl = model_tl.predict(test_data)\n",
    "pred_ts = model_ts.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 1 0 1 1\n"
     ]
    }
   ],
   "source": [
    "print(label, pred_cl[0], pred_cs[0], pred_tl[0], pred_ts[0])"
   ]
  }
 ]
}